# ë¡œì»¬ Whisper STT ê°€ì´ë“œ

OpenAI API ëŒ€ì‹  ì˜¨í”„ë ˆë¯¸ìŠ¤ Faster-Whisper ëª¨ë¸ì„ ì‚¬ìš©í•œ STT êµ¬í˜„ì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨
- [ì„±ëŠ¥ ë¹„êµ](#ì„±ëŠ¥-ë¹„êµ)
- [ì„¤ì¹˜ ë°©ë²•](#ì„¤ì¹˜-ë°©ë²•)
- [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
- [í…ŒìŠ¤íŠ¸](#í…ŒìŠ¤íŠ¸)
- [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)

---

## ğŸ”¥ ì„±ëŠ¥ ë¹„êµ

### ë°°í¬ ë°©ì‹ë³„ ì„±ëŠ¥ ì°¨ì´

| ë°©ì‹ | ì¶”ë¡  ì†ë„ | ë©”ëª¨ë¦¬ ì˜¤ë²„í—¤ë“œ | ì¥ì  |
|------|----------|----------------|------|
| **ì„œë²„ ì§ì ‘ ì„¤ì¹˜** | â­â­â­ ê°€ì¥ ë¹ ë¦„ | ì—†ìŒ | ì˜¤ë²„í—¤ë“œ ì œë¡œ |
| **ë„ì»¤ ì»¨í…Œì´ë„ˆ (ê¶Œì¥)** | â­â­â­ ê±°ì˜ ë™ì¼ | ~100MB | í™˜ê²½ ì¼ê´€ì„±, ë°°í¬ í¸ë¦¬ |
| **ë¶„ë¦¬ëœ ì»¨í…Œì´ë„ˆ** | â­â­ 20-100ms ì¶”ê°€ | ì»¨í…Œì´ë„ˆ 2ê°œ | ë…ë¦½ ìŠ¤ì¼€ì¼ë§ |

**â†’ í˜„ì¬ êµ¬ì¡°ì— í†µí•© (ë„ì»¤ ì»¨í…Œì´ë„ˆ ë°©ì‹) ê¶Œì¥**

### Faster-Whisper vs OpenAI API

| í•­ëª© | Faster-Whisper | OpenAI API |
|------|----------------|------------|
| ì†ë„ | 5-10ë°° ë¹ ë¦„ | ë„¤íŠ¸ì›Œí¬ ì§€ì—° ìˆìŒ |
| ë¹„ìš© | ë¬´ë£Œ (ì„œë²„ ë¹„ìš©ë§Œ) | ë¶„ë‹¹ ê³¼ê¸ˆ |
| ì •í™•ë„ | ë™ì¼ (ê°™ì€ ëª¨ë¸) | ë™ì¼ |
| ë°ì´í„° í”„ë¼ì´ë²„ì‹œ | âœ… ì˜¨í”„ë ˆë¯¸ìŠ¤ | âŒ ì™¸ë¶€ ì „ì†¡ |

---

## ğŸš€ ì„¤ì¹˜ ë°©ë²•

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

`requirements.txt`ì— `faster-whisper>=1.0.0`ì´ ì´ë¯¸ ì¶”ê°€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### 2. ë¼ìš°í„° ë“±ë¡

`app.py`ì— ë‹¤ìŒ ë¼ì¸ì„ ì¶”ê°€í•˜ì„¸ìš”:

```python
from routers.stt_router_local import router as stt_router_local

# ë¼ìš°í„° ë“±ë¡
app.include_router(stt_router_local, prefix="/api")
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì„ íƒì‚¬í•­)

`config/.env` íŒŒì¼ì— ì¶”ê°€:

```env
# Whisper ëª¨ë¸ ì„¤ì •
WHISPER_MODEL_SIZE=medium    # tiny/base/small/medium/large-v3
WHISPER_DEVICE=cpu           # cpu or cuda
WHISPER_COMPUTE_TYPE=int8    # int8/float16/float32
```

---

## ğŸ“– ì‚¬ìš© ë°©ë²•

### API ì—”ë“œí¬ì¸íŠ¸

#### 1. í—¬ìŠ¤ì²´í¬
```bash
GET /api/stt/local/health
```

ì‘ë‹µ:
```json
{
  "status": "healthy",
  "model_size": "medium",
  "device": "cpu",
  "compute_type": "int8",
  "model_loaded": true
}
```

#### 2. ì „ì²´ í…ìŠ¤íŠ¸ ë³€í™˜
```bash
POST /api/stt/local/full
Content-Type: multipart/form-data

file: <audio_file>
language: ko
```

ì‘ë‹µ:
```json
{
  "text": "ë³€í™˜ëœ ì „ì²´ í…ìŠ¤íŠ¸",
  "segments": [
    {
      "start": 0.0,
      "end": 3.5,
      "text": "ì•ˆë…•í•˜ì„¸ìš”",
      "avg_logprob": -0.234,
      "no_speech_prob": 0.001
    }
  ],
  "language": "ko",
  "duration": 1.23
}
```

#### 3. ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜
```bash
POST /api/stt/local/stream
Content-Type: multipart/form-data

file: <audio_file>
language: ko
```

ì‘ë‹µ (Server-Sent Events):
```
data: {"start": 0.0, "end": 3.5, "text": "ì•ˆë…•í•˜ì„¸ìš”", ...}
data: {"start": 3.5, "end": 7.2, "text": "ë°˜ê°‘ìŠµë‹ˆë‹¤", ...}
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### 1. ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ í…ŒìŠ¤íŠ¸

```bash
# ìƒ˜í”Œ ì˜¤ë””ì˜¤ íŒŒì¼ ì¤€ë¹„
# (mp3, wav, m4a, flac ë“± ì§€ì›)

python test_local_stt_direct.py ./sample.mp3
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
ğŸ”„ Loading Whisper model: medium on cpu with int8
âœ… Whisper model loaded in 2.34s

ğŸ¤ Transcribing: ./sample.mp3
ğŸŒ Detected language: ko (probability: 0.99)

[ì„¸ê·¸ë¨¼íŠ¸ 1]
  ì‹œê°„: 0.00s ~ 3.50s
  í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”
  í™•ë¥ : -0.234 (ë¬´ìŒ í™•ë¥ : 0.001)

âœ… ì „ì²´ í…ìŠ¤íŠ¸:
ì•ˆë…•í•˜ì„¸ìš” ë°˜ê°‘ìŠµë‹ˆë‹¤

ğŸ“Š í†µê³„:
  - ì–¸ì–´: ko
  - ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: 2
  - ì²˜ë¦¬ ì‹œê°„: 0.85ì´ˆ
  - ì˜¤ë””ì˜¤ ê¸¸ì´: 7.20ì´ˆ
  - ì²˜ë¦¬ ì†ë„: 8.47x ì‹¤ì‹œê°„
```

### 2. FastAPI ì„œë²„ í…ŒìŠ¤íŠ¸

**ì„œë²„ ì‹¤í–‰:**
```bash
uvicorn app:app --reload --port 8000
```

**API í…ŒìŠ¤íŠ¸:**
```bash
python test_local_stt_api.py ./sample.mp3
```

**cURL í…ŒìŠ¤íŠ¸:**
```bash
# í—¬ìŠ¤ì²´í¬
curl http://localhost:8000/api/stt/local/health

# ì „ì²´ í…ìŠ¤íŠ¸
curl -X POST http://localhost:8000/api/stt/local/full \
  -F "file=@sample.mp3" \
  -F "language=ko"
```

---

## âš™ï¸ í™˜ê²½ ì„¤ì •

### ëª¨ë¸ í¬ê¸°ë³„ ì„±ëŠ¥

| ëª¨ë¸ | í¬ê¸° | ë©”ëª¨ë¦¬ (CPU) | ì†ë„ | í•œêµ­ì–´ ì •í™•ë„ | ì¶”ì²œ |
|------|------|-------------|------|--------------|------|
| **tiny** | ~40MB | ~1GB | â­â­â­ | ë‚®ìŒ | í…ŒìŠ¤íŠ¸ìš© |
| **base** | ~75MB | ~1GB | â­â­â­ | ë³´í†µ | ì‹¤ì‹œê°„ |
| **small** | ~500MB | ~2GB | â­â­â­ | ì–‘í˜¸ | **ì‹¤ì‹œê°„** âœ… |
| **medium** | ~1.5GB | ~5GB | â­â­ | ìš°ìˆ˜ | **ì •í™•ë„ ì¤‘ì‹œ** âœ… |
| **large-v3** | ~3GB | ~10GB | â­ | ìµœê³  | ë°°ì¹˜ ì²˜ë¦¬ |

**ê¶Œì¥ ì„¤ì • (ì •í™•ë„ ìš°ì„ ):**
```env
WHISPER_MODEL_SIZE=medium
WHISPER_DEVICE=cpu
WHISPER_COMPUTE_TYPE=int8
```

### GPU ì‚¬ìš© (ì„ íƒì‚¬í•­)

CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ:
```env
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=float16  # GPUëŠ” float16 ê¶Œì¥
```

**ì†ë„ í–¥ìƒ:** ~2-3ë°° ë¹ ë¦„

---

## ğŸ¯ ì •í™•ë„ í–¥ìƒ ì„¤ì •

í˜„ì¬ `stt_service_local.py`ì— ì ìš©ëœ ì„¤ì •:

```python
model.transcribe(
    audio_file_path,
    language="ko",
    beam_size=10,          # ë¹” ì„œì¹˜ í¬ê¸° (5â†’10, ëŠë¦¬ì§€ë§Œ ì •í™•)
    best_of=5,             # ìƒìœ„ 5ê°œ í›„ë³´ ì¤‘ ìµœì„  ì„ íƒ
    temperature=0.0,       # ê²°ì •ì  ì¶œë ¥ (0.0 = ê°€ì¥ ì •í™•)
    condition_on_previous_text=True,  # ì´ì „ ì»¨í…ìŠ¤íŠ¸ í™œìš©
    vad_filter=True,       # ë¬´ìŒ ì œê±°
)
```

**ì •í™•ë„ vs ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„:**
- `beam_size=10` â†’ ëŠë¦¬ì§€ë§Œ ì •í™•
- `beam_size=5` â†’ ë¹ ë¥´ì§€ë§Œ ëœ ì •í™•
- `beam_size=1` â†’ ê°€ì¥ ë¹ ë¥´ì§€ë§Œ ë¶€ì •í™•

---

## ğŸ³ Docker ë°°í¬

### Dockerfile (ì´ë¯¸ ì¤€ë¹„ë¨)

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

### ë¹Œë“œ ë° ì‹¤í–‰

```bash
# ë¹Œë“œ
docker-compose build

# ì‹¤í–‰
docker-compose up -d

# ë¡œê·¸ í™•ì¸
docker-compose logs -f ai-cloud
```

**ìµœì´ˆ ì‹¤í–‰ ì‹œ:**
- Whisper ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤ (~1.5GB for medium)
- ë‹¤ìš´ë¡œë“œëŠ” 1íšŒë§Œ ë°œìƒ (`./models/whisper`ì— ìºì‹œë¨)

---

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

í…ŒìŠ¤íŠ¸ í™˜ê²½: CPU (Intel i7), medium ëª¨ë¸

| ì˜¤ë””ì˜¤ ê¸¸ì´ | ì²˜ë¦¬ ì‹œê°„ | ì‹¤ì‹œê°„ ë°°ìˆ˜ |
|-------------|----------|------------|
| 10ì´ˆ | 1.2ì´ˆ | 8.3x |
| 30ì´ˆ | 3.5ì´ˆ | 8.6x |
| 1ë¶„ | 7.1ì´ˆ | 8.5x |
| 5ë¶„ | 35ì´ˆ | 8.6x |

**ê²°ë¡ :** ì‹¤ì‹œê°„ë³´ë‹¤ **ì•½ 8-9ë°° ë¹ ë¥´ê²Œ** ì²˜ë¦¬ ê°€ëŠ¥

---

## â“ FAQ

**Q: ëª¨ë¸ì´ ë„ˆë¬´ í¬ë©´ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?**
A: `small` ëª¨ë¸ ì‚¬ìš© (~500MB, í•œêµ­ì–´ ì„±ëŠ¥ ì–‘í˜¸)

**Q: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì´ ê°€ëŠ¥í•œê°€ìš”?**
A: ì„¸ê·¸ë¨¼íŠ¸ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ê°€ëŠ¥ (ì™„ì „ ì‹¤ì‹œê°„ì€ ì•„ë‹˜)

**Q: ì—¬ëŸ¬ ì–¸ì–´ë¥¼ ë™ì‹œì— ì¸ì‹í•  ìˆ˜ ìˆë‚˜ìš”?**
A: `language` íŒŒë¼ë¯¸í„° ì—†ì´ í˜¸ì¶œí•˜ë©´ ìë™ ê°ì§€

**Q: í™”ì ë¶„ë¦¬(Diarization)ê°€ ê°€ëŠ¥í•œê°€ìš”?**
A: Faster-WhisperëŠ” ê¸°ë³¸ ì§€ì› ì•ˆ í•¨ (ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
cloud/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ stt_service.py          # ê¸°ì¡´ OpenAI API ë²„ì „
â”‚   â””â”€â”€ stt_service_local.py    # ğŸ†• ë¡œì»¬ Whisper ë²„ì „
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ stt_router.py           # ê¸°ì¡´ ë¼ìš°í„°
â”‚   â””â”€â”€ stt_router_local.py     # ğŸ†• ë¡œì»¬ Whisper ë¼ìš°í„°
â”œâ”€â”€ test_local_stt_direct.py    # ğŸ†• ì§ì ‘ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_local_stt_api.py       # ğŸ†• API í…ŒìŠ¤íŠ¸
â”œâ”€â”€ models/
â”‚   â””â”€â”€ whisper/                # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜
â””â”€â”€ LOCAL_STT_GUIDE.md          # ğŸ†• ì´ ê°€ì´ë“œ
```

---

## ğŸ‰ ì™„ë£Œ!

ì´ì œ ì˜¨í”„ë ˆë¯¸ìŠ¤ Whisper STTë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ë‹¤ìŒ ë‹¨ê³„:**
1. `app.py`ì— ë¼ìš°í„° ë“±ë¡
2. `docker-compose up` ì‹¤í–‰
3. í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¡œ í™•ì¸

**ë¬¸ì˜:** [í”„ë¡œì íŠ¸ ì´ìŠˆ íŠ¸ë˜ì»¤]

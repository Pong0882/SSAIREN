services:
  ai-cloud:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-cloud
    restart: unless-stopped
    ports:
      - "8000:8000"
    env_file:
      - ./config/.env
    environment:
      - TZ=Asia/Seoul
      # PyTorch 스레드 제한 (4코어 CPU 환경 최적화)
      - OMP_NUM_THREADS=2
      - MKL_NUM_THREADS=2
      - OPENBLAS_NUM_THREADS=2
    volumes:
      - ./models:/app/models
      - whisper-models:/app/models/whisper # Whisper 모델 캐시
    # 리소스 제한 (6GB RAM, 4코어 CPU 환경)
    deploy:
      resources:
        limits:
          cpus: '3'           # 4코어 중 3코어 할당 (1코어는 시스템용)
          memory: 5G          # 6GB 중 5GB 할당 (안전 마진)
        reservations:
          cpus: '1'           # 최소 1코어 보장
          memory: 2G          # 최소 2GB 보장
    # 메모리 스왑 비활성화
    mem_swappiness: 0
    # OOM 방지
    oom_kill_disable: false
    networks:
      - ssairen-net
    healthcheck:
      test: [ "CMD-SHELL", "python -c \"import requests; requests.get('http://localhost:8000/')\" || exit 1" ]
      interval: 30s
      timeout: 3s
      start_period: 10s
      retries: 3

  # Cloudflare Tunnel (네트워크 포트 차단 시 ngrok 사용)
  # cloudflared:
  #   image: cloudflare/cloudflared:latest
  #   container_name: cloudflared-tunnel
  #   restart: unless-stopped
  #   command: ["tunnel", "--protocol", "http2", "run"]
  #   env_file:
  #     - ./config/.env
  #   environment:
  #     - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
  #   networks:
  #     - ssairen-net
  #   depends_on:
  #     - ai-cloud

  ngrok:
    image: ngrok/ngrok:latest
    container_name: ngrok-tunnel
    restart: unless-stopped
    command:
      - "start"
      - "--all"
      - "--config"
      - "/etc/ngrok.yml"
    volumes:
      - ./config/ngrok.yml:/etc/ngrok.yml
    ports:
      - "4040:4040" # ngrok 웹 인터페이스
    networks:
      - ssairen-net
    depends_on:
      - ai-cloud

volumes:
  whisper-models:
    # Whisper 모델 저장용 볼륨

networks:
  ssairen-net:
    driver: bridge

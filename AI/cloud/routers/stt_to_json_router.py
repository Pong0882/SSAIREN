"""
STT â†’ JSON ì¶”ì¶œ í†µí•© ë¼ìš°í„°
ìŒì„± íŒŒì¼ â†’ STT â†’ íŒŒì¸íŠœë‹ëœ LLM â†’ JSON

ì „ì²´ í”Œë¡œìš°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
"""
from fastapi import APIRouter, UploadFile, File, HTTPException
from pydantic import BaseModel, Field
from typing import Dict, Any
from services.stt_service import transcribe_audio_stream
from services.lora_llm_service import get_lora_llm_service
import tempfile
import os

router = APIRouter(prefix="/stt-to-json", tags=["STT to JSON"])

class ConversationToJsonRequest(BaseModel):
    """ëŒ€í™” í…ìŠ¤íŠ¸ â†’ JSON ìš”ì²­"""
    conversation: str = Field(..., description="ëŒ€í™” í…ìŠ¤íŠ¸ (STT ê²°ê³¼ ë˜ëŠ” ì§ì ‘ ì…ë ¥)")
    max_new_tokens: int = Field(700, ge=400, le=1500, description="ìµœëŒ€ ìƒì„± í† í°")
    temperature: float = Field(0.1, ge=0.0, le=1.0, description="ìƒ˜í”Œë§ ì˜¨ë„")

class SttToJsonResponse(BaseModel):
    """STT â†’ JSON ì‘ë‹µ"""
    success: bool
    stt_text: str = Field(..., description="STTë¡œ ë³€í™˜ëœ í…ìŠ¤íŠ¸")
    extracted_json: Dict[str, Any] = Field(..., description="ì¶”ì¶œëœ EMS JSON")
    raw_output: str = Field(..., description="LLM ì›ë³¸ ì¶œë ¥")

@router.post("/audio-to-json", response_model=SttToJsonResponse)
async def audio_to_json(audio_file: UploadFile = File(...)):
    """
    ìŒì„± íŒŒì¼ â†’ STT â†’ JSON ì¶”ì¶œ (ì „ì²´ í”Œë¡œìš°)
    
    ## í”„ë¡œì„¸ìŠ¤
    1. ìŒì„± íŒŒì¼ ì—…ë¡œë“œ
    2. Whisper STTë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
    3. íŒŒì¸íŠœë‹ëœ Qwen ëª¨ë¸ë¡œ JSON ì¶”ì¶œ
    4. ê²°ê³¼ ë°˜í™˜
    
    ## ì§€ì› í˜•ì‹
    - wav, mp3, m4a, webm ë“±
    """
    try:
        # 1. ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            content = await audio_file.read()
            tmp_file.write(content)
            tmp_path = tmp_file.name
        
        try:
            # 2. STT ì²˜ë¦¬
            print(f"ğŸ¤ STT ì²˜ë¦¬ ì‹œì‘: {audio_file.filename}")
            stt_result = []
            for chunk in transcribe_audio_stream(tmp_path, language="ko"):
                stt_result.append(chunk)
            
            # STT ê²°ê³¼ í•©ì¹˜ê¸°
            stt_text = "".join(stt_result)
            print(f"âœ… STT ì™„ë£Œ: {len(stt_text)}ì")
            
            # 3. LLMìœ¼ë¡œ JSON ì¶”ì¶œ
            print(f"ğŸ¤– JSON ì¶”ì¶œ ì‹œì‘")
            llm_service = get_lora_llm_service()
            result = llm_service.extract_json_from_conversation(
                conversation=stt_text,
                max_new_tokens=700,
                temperature=0.1
            )
            
            if result["success"]:
                print(f"âœ… JSON ì¶”ì¶œ ì™„ë£Œ")
                return SttToJsonResponse(
                    success=True,
                    stt_text=stt_text,
                    extracted_json=result["json"],
                    raw_output=result["raw_text"]
                )
            else:
                print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {result['error']}")
                raise HTTPException(
                    status_code=500,
                    detail=f"JSON íŒŒì‹± ì‹¤íŒ¨: {result['error']}"
                )
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

@router.post("/text-to-json")
async def text_to_json(request: ConversationToJsonRequest):
    """
    ëŒ€í™” í…ìŠ¤íŠ¸ â†’ JSON ì¶”ì¶œ (STT ê²°ê³¼ ì§ì ‘ ì…ë ¥)
    
    ## ìš©ë„
    - STTê°€ ì´ë¯¸ ì™„ë£Œëœ ê²½ìš°
    - í…ŒìŠ¤íŠ¸ìš© ëŒ€í™” ì§ì ‘ ì…ë ¥
    """
    try:
        print(f"ğŸ¤– JSON ì¶”ì¶œ ì‹œì‘ (ëŒ€í™” ê¸¸ì´: {len(request.conversation)}ì)")
        
        llm_service = get_lora_llm_service()
        result = llm_service.extract_json_from_conversation(
            conversation=request.conversation,
            max_new_tokens=request.max_new_tokens,
            temperature=request.temperature
        )
        
        if result["success"]:
            print(f"âœ… JSON ì¶”ì¶œ ì™„ë£Œ")
            return {
                "success": True,
                "extracted_json": result["json"],
                "raw_output": result["raw_text"]
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=f"JSON íŒŒì‹± ì‹¤íŒ¨: {result['error']}"
            )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

@router.post("/reload-model")
async def reload_model(adapter_path: str):
    """
    ìƒˆë¡œìš´ LoRA ëª¨ë¸ë¡œ êµì²´
    
    ## ì‚¬ìš© ì‹œì 
    - íŒŒì¸íŠœë‹ ì™„ë£Œ í›„ ìƒˆ ëª¨ë¸ ì ìš©
    - ëª¨ë¸ ë²„ì „ ì—…ê·¸ë ˆì´ë“œ
    
    ## ì˜ˆì‹œ
    ```
    POST /stt-to-json/reload-model?adapter_path=./models/ems-lora-checkpoint-v2
    ```
    """
    try:
        llm_service = get_lora_llm_service()
        llm_service.reload_model(adapter_path)
        return {
            "success": True,
            "message": f"ëª¨ë¸ ì¬ë¡œë“œ ì™„ë£Œ: {adapter_path}"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ì¬ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

@router.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    try:
        llm_service = get_lora_llm_service()
        return {
            "status": "healthy",
            "model_loaded": llm_service._model is not None,
            "device": llm_service._device
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"ì„œë¹„ìŠ¤ ë¶ˆê°€: {str(e)}")


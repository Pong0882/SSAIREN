package com.example.ssairen_app.utils

import android.content.Context
import android.content.Intent
import android.os.Bundle
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.util.Log
import java.util.Locale

/**
 * Android Speech Recognitionì„ ì‚¬ìš©í•œ STT í—¬í¼ í´ë˜ìŠ¤
 */
class SpeechToTextHelper(
    private val context: Context,
    private val onResult: (String) -> Unit,
    private val onPartialResult: (String) -> Unit = {},
    private val onError: (String) -> Unit = {}
) {
    private var speechRecognizer: SpeechRecognizer? = null
    private val recognizerIntent: Intent
    private var isListening = false
    private val accumulatedText = StringBuilder()

    companion object {
        private const val TAG = "SpeechToTextHelper"
    }

    init {
        // SpeechRecognizer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(context)

        // RecognizerIntent ì„¤ì •
        recognizerIntent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.KOREAN)
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true)
            putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 1)
        }

        // RecognitionListener ì„¤ì •
        speechRecognizer?.setRecognitionListener(object : RecognitionListener {
            override fun onReadyForSpeech(params: Bundle?) {
                Log.d(TAG, "âœ… Ready for speech")
            }

            override fun onBeginningOfSpeech() {
                Log.d(TAG, "ğŸ¤ Speech started")
            }

            override fun onRmsChanged(rmsdB: Float) {
                // ìŒì„± ë ˆë²¨ ë³€í™” (í•„ìš”ì‹œ ì‚¬ìš©)
            }

            override fun onBufferReceived(buffer: ByteArray?) {
                // ë²„í¼ ìˆ˜ì‹  (í•„ìš”ì‹œ ì‚¬ìš©)
            }

            override fun onEndOfSpeech() {
                Log.d(TAG, "ğŸ›‘ Speech ended")
            }

            override fun onError(error: Int) {
                val errorMessage = when (error) {
                    SpeechRecognizer.ERROR_AUDIO -> "ì˜¤ë””ì˜¤ ì—ëŸ¬"
                    SpeechRecognizer.ERROR_CLIENT -> "í´ë¼ì´ì–¸íŠ¸ ì—ëŸ¬"
                    SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> "ê¶Œí•œ ë¶€ì¡±"
                    SpeechRecognizer.ERROR_NETWORK -> "ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬"
                    SpeechRecognizer.ERROR_NETWORK_TIMEOUT -> "ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ"
                    SpeechRecognizer.ERROR_NO_MATCH -> "ì¸ì‹ ì‹¤íŒ¨"
                    SpeechRecognizer.ERROR_RECOGNIZER_BUSY -> "ìŒì„±ì¸ì‹ ì„œë¹„ìŠ¤ ì‚¬ìš© ì¤‘"
                    SpeechRecognizer.ERROR_SERVER -> "ì„œë²„ ì—ëŸ¬"
                    SpeechRecognizer.ERROR_SPEECH_TIMEOUT -> "ìŒì„± ì…ë ¥ ì—†ìŒ"
                    else -> "ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬: $error"
                }
                Log.e(TAG, "âŒ Error: $errorMessage")
                onError(errorMessage)

                // ì—ëŸ¬ ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ ì¬ì‹œì‘ (íƒ€ì„ì•„ì›ƒì´ë‚˜ ë§¤ì¹˜ ì—†ìŒ ì œì™¸)
                if (error != SpeechRecognizer.ERROR_NO_MATCH &&
                    error != SpeechRecognizer.ERROR_SPEECH_TIMEOUT &&
                    isListening) {
                    restartListening()
                }
            }

            override fun onResults(results: Bundle?) {
                val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                if (!matches.isNullOrEmpty()) {
                    val text = matches[0]
                    Log.d(TAG, "ğŸ“ Final result: $text")

                    // ëˆ„ì ëœ í…ìŠ¤íŠ¸ì— ì¶”ê°€
                    if (accumulatedText.isNotEmpty()) {
                        accumulatedText.append(" ")
                    }
                    accumulatedText.append(text)

                    onResult(accumulatedText.toString())

                    // ê³„ì† ë“£ê¸° ìœ„í•´ ì¬ì‹œì‘
                    if (isListening) {
                        restartListening()
                    }
                }
            }

            override fun onPartialResults(partialResults: Bundle?) {
                val matches = partialResults?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                if (!matches.isNullOrEmpty()) {
                    val text = matches[0]
                    Log.d(TAG, "ğŸ“ Partial result: $text")
                    onPartialResult(text)
                }
            }

            override fun onEvent(eventType: Int, params: Bundle?) {
                // ì´ë²¤íŠ¸ ì²˜ë¦¬ (í•„ìš”ì‹œ ì‚¬ìš©)
            }
        })
    }

    /**
     * ìŒì„± ì¸ì‹ ì‹œì‘
     */
    fun startListening() {
        if (!isListening) {
            isListening = true
            accumulatedText.clear()
            Log.d(TAG, "ğŸ¤ Starting speech recognition")
            speechRecognizer?.startListening(recognizerIntent)
        }
    }

    /**
     * ìŒì„± ì¸ì‹ ì¤‘ì§€
     */
    fun stopListening() {
        if (isListening) {
            isListening = false
            Log.d(TAG, "ğŸ›‘ Stopping speech recognition")
            speechRecognizer?.stopListening()
        }
    }

    /**
     * ìŒì„± ì¸ì‹ ì¬ì‹œì‘ (ì—°ì† ì¸ì‹ì„ ìœ„í•´)
     */
    private fun restartListening() {
        speechRecognizer?.cancel()
        Thread.sleep(100) // ì§§ì€ ë”œë ˆì´
        speechRecognizer?.startListening(recognizerIntent)
    }

    /**
     * ëˆ„ì ëœ ì „ì²´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
     */
    fun getAccumulatedText(): String {
        return accumulatedText.toString()
    }

    /**
     * ëˆ„ì ëœ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
     */
    fun clearAccumulatedText() {
        accumulatedText.clear()
    }

    /**
     * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
     */
    fun destroy() {
        speechRecognizer?.destroy()
        speechRecognizer = null
    }
}
